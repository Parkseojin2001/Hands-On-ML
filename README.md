# Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow

## PART 1 머신러닝

#### Chapter 1 한눈에 보는 머신러닝
- [x] 1.1 머신러닝이란?
- [x] 1.2 왜 머신러닝을 사용하는가?
- [x] 1.3 애플리케이션 사례
- [x] 1.4 머신러닝 시스템의 종류
- [x] 1.5 머신러닝의 주요 도전 과제
- [x] 1.6 테스트와 검증
#### Chapter 2 머신러닝 프로젝트 처음부터 끝까지
- [x] 2.1실제 데이터로 작업하기
- [x] 2.2 큰 그림 보기
- [x] 2.3 데이터 가져오기
- [x] 2.4 데이터 이해를 위한 탐색과 시각화
- [x] 2.5 머신러닝 알고리즘을 위한 데이터 준비
- [x] 2.6 모델 선택과 훈련
- [x] 2.7 모델 세부 튜닝
- [ ] 2.8 론칭, 모니터링, 시스템 유지 보수
#### Chapter 3 분류
- [ ] 3.1 MNIST
- [ ] 3.2 이진 분류기 훈련
- [ ] 3.3 성능 측정
- [ ] 3.4 다중 분석
- [ ] 3.5 에러 분석
- [ ] 3.6 다중 레이블 분류
- [ ] 3.7 다중 출력 분류
#### Chpater 4 모델 훈련
- [ ] 4.1 선형 회귀
- [ ] 4.2 경사 하강법
- [ ] 4.3 다항 회귀
- [ ] 4.4 학습 곡선
- [ ] 4.5 규제가 있는 선형 모델
- [ ] 4.6 로지스틱 회귀
#### Chapter 5 서포트 벡터 머신
- [ ] 5.1 선형 SVM 분류
- [ ] 5.2 비선형 SVM 분류
- [ ] 5.3 SVM 회귀
- [ ] 5.4 SVM 이론
#### Chapter 6 결정 트리
- [ ] 6.1 결정 트리 학습과 시각화
- [ ] 6.2 예측하기
- [ ] 6.3 클래스 확률 추정
- [ ] 6.4 CART 훈련 알고리즘
- [ ] 6.5 계산 복잡도
- [ ] 6.6 지니 불순도 또는 엔트로피?
- [ ] 6.7 규제 매개변수
- [ ] 6.8 회귀
- [ ] 6.9 불안정성
#### Chapter 7 앙상블 학습과 랜덤 포레스트
- [ ] 7.1 투표 기반 분류기
- [ ] 7.2 배깅과 페이스팅
- [ ] 7.3 랜덤 패치와 랜덤 서브스페이스
- [ ] 7.4 랜덤 포레스트
- [ ] 7.5 부스팅
- [ ] 7.6 스태킹
#### Chapter 8 차원 축소
- [ ] 8.1 차원의 저주
- [ ] 8.2 차원 축소를 위한 접근 방법
- [ ] 8.3 PCA
- [ ] 8.4 커널 PCA
- [ ] 8.5 LLE
- [ ] 8.6 다른 차원 축소 기법
#### Chapter 9 비지도 학습
- [ ] 9.1 군집
- [ ] 9.2 가우시안 혼합
